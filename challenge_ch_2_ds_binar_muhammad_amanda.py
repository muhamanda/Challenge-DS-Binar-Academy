# -*- coding: utf-8 -*-
"""Challenge Ch.2 DS Binar - Muhammad Amanda.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AkhWb8J3El8KdxW-Dp82YAxNIDm7tFZF

# **Customer Churn Classification**
****

---

## **Domain Proyek**

Perkembangan industri telekomunikasi sangatlah cepat, hal ini dapat dilihat dari perilaku masyarakat yang menggunakan internet dalam berkomunikasi.
Perilaku ini menyebabkan banyaknya perusahaan telekomunikasi dan meningkatnya internet service provider yang dapat menimbulkan persaingan antar provider.
Pelanggan memiliki hak dalam memilih provider yang sesuai dan dapat beralih dari provider sebelumnya yang diartikan sebagai Customer Churn. Peralihan ini dapat menyebabkan berkurangnya pendapatan bagi perusahaan telekomunikasi sehingga penting untuk ditangani.

## **Business understanding**

Suatu perusahaan penyedia jasa (provider) memiliki data terkait customer, namun data tersebut masih sulit untuk melihat pola apakah di waktu mendatang seorang customer akan churn atau tidak, untuk kepentingan pengembangan selanjutnya maka dibutuhkan sebuah model yang bisa mengklasifikasi data customer di perusahaan provider, hal ini diperlukan agar data yang ada bisa lebih bermanfaat lagi bukan hanya sekedar tumpukan data yang minim informasi.

### Problem Statements
*   Dari serangkaian fitur yang ada, fitur apa yang paling berpengaruh terhadap customer churn?
*   Apakah seorang customer berpotensi chrun dengan karakteristik atau fitur tertentu?

### Goals
*   Mengetahui fitur yang paling berkorelasi dengan kondisi customer churn.
*   Membuat model machine learning yang dapat memprediksi apakah customer berpotensi churn seakurat mungkin berdasarkan fitur-fitur yang ada.

### Metodologi
Prediksi kondisi customer churn adalah tujuan yang ingin dicapai. Seperti yang kita tahu, churn merupakan variabel kategorik. Dalam predictive analytics, saat membuat prediksi variabel kategorik artinya Anda sedang menyelesaikan permasalahan klasifikasi. Oleh karena itu, metodologi pada proyek ini adalah membangun model klasifikasi dengan kondisi customer churn sebagai target.

### Metrik
Metrik digunakan untuk mengevaluasi seberapa baik model Anda dalam memprediksi customer churn. Untuk kasus klasifikasi, metrik yang biasanya digunakan adalah accuracy.

## **Data understanding**

Data yang Anda gunakan pada proyek kali ini adalah **Customer Churn**.

Dataset ini memiliki **4.250** sampel customer dengan berbagai karakteristik. Karakteristik yang dimaksud di sini adalah fitur numerik maupun non-numerik.

### Data Loading

Supaya isi dataset lebih mudah dipahami, kita perlu melakukan proses loading data terlebih dahulu. Dataset yang akan kita gunakan bernama train.csv dan selanjutnya akan dilakukan prediksi untuk data test.csv dari model yang telah dibangun.
"""

# Upload file dataset train.csv dan test.csv
from google.colab import files
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
# Import library yang dibutuhkan
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV

# Baca file dataset
train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')

train

"""Output kode di atas memberikan informasi sebagai berikut:

*   Ada 4.250 baris (records atau jumlah pengamatan) dalam dataset.
*   Terdapat 20 kolom yaitu: state,	account_length,	area_code,	international_plan,	voice_mail_plan,	number_vmail_messages,	total_day_minutes,	total_day_calls,	total_day_charge, total_eve_minutes,	total_eve_calls,	total_eve_charge,	total_night_minutes,	total_night_calls,	total_night_charge,	total_intl_minutes,	total_intl_calls,	total_intl_charge,	number_customer_service_calls, dan	churn.

### Exploratory Data Analysis - Deskripsi Variabel

Exploratory data analysis (EDA) merupakan proses investigasi awal pada data untuk menganalisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data.

Secara umum, Anda dapat melakukan proses EDA untuk menjawab beberapa pertanyaan berikut:
*   Apa saja jenis variabel pada dataset?
*   Apakah ada missing value?
*   Apakah ada fitur yang tidak berguna (redundant)?
*   Bagaimana distribusi variabel dalam dataset?

Dalam menjawab pertanyaan-pertanyaan di atas, Anda perlu melakukan beberapa hal pada data.
"""

train.info()

"""Dari output terlihat bahwa:
*   Terdapat 5 kolom dengan tipe object, 4 diantaranya yaitu: state,	area_code,	international_plan,	dan voice_mail_plan. Kolom ini merupakan categorical features (fitur non-numerik). Satu lainnya adalah churn yang merupakan fitur target kita.
*   Terdapat 15 kolom numerik dengan tipe data float64 sebanyak 8 kolom yaitu: total_day_minutes,	total_day_charge, total_eve_minutes,	total_eve_charge,	total_night_minutes,	total_night_charge,	total_intl_minutes,	dan total_intl_charge. Dan 7 sisanya bertipe data int64 yaitu: account_length,	number_vmail_messages, total_day_calls, total_eve_calls, total_night_calls, total_intl_calls, dan number_customer_service_calls.
*   Tidak ada missing value dari dataset.


Definisi dari masing-masing kolom/variabel/fitur diketahui sebagai berikut:

<img src="https://user-images.githubusercontent.com/70586158/196335467-6b93f616-2f42-4926-8ed9-ae856805f5b6.png" width="1200">


"""

train.describe()

"""Fungsi describe() memberikan informasi statistik pada masing-masing kolom, antara lain:
*   Count  adalah jumlah sampel pada data.
*   Mean adalah nilai rata-rata.
*   Std adalah standar deviasi.
*   Min yaitu nilai minimum setiap kolom.
*   25% adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
*   50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
*   75% adalah kuartil ketiga.
*   Max adalah nilai maksimum.

### Exploratory Data Analysis - Menangani Missing Value dan Outliers

Selama pengumpulan data tidak jarang ditemukan hilangnya beberapa data yang telah diperoleh. Hal ini disebut missing value. Ada beberapa teknik untuk menangani missing value antara lain:
*   Imputation, mengisi missing value dengan nilai konstanta, mean, median, modus, dll.
*   Drop data, bisa dilakukan penghapusan baris data atau kolom data.

Dari hasil fungsi info(), deskripsi masing-masing kolom menunjukkan data yang lengkap. Hal tersebut mengindikasikan tidak ada missing value pada dataset jadi tidak perlu dilakukan penanganan missing value. Dapat kita cek kembali sebagai berikut.
"""

train.isnull().sum()

"""Beberapa pengamatan dalam satu set data kadang berada di luar lingkungan pengamatan lainnya. Pengamatan seperti itu disebut outlier. Outliers adalah sampel yang nilainya sangat jauh dari cakupan umum data utama. Ia adalah hasil pengamatan yang kemunculannya sangat jarang dan berbeda dari data hasil pengamatan lainnya.

Ada beberapa teknik untuk menangani outliers, antara lain:
*   Hypothesis Testing
*   Z-score method
*   IQR Method

Pada kasus ini, Anda akan mendeteksi outliers dengan teknik visualisasi data (boxplot). Kemudian, Anda akan menangani outliers dengan teknik IQR method.


1. Fitur account_length
"""

sns.boxplot(x=train['account_length'])

"""2. Fitur number_vmail_messages"""

sns.boxplot(x=train['number_vmail_messages'])

"""3. Fitur total_day_minutes"""

sns.boxplot(x=train['total_day_minutes'])

"""4. Fitur total_day_calls"""

sns.boxplot(x=train['total_day_calls'])

"""5. Fitur total_day_charge"""

sns.boxplot(x=train['total_day_charge'])

"""6. Fitur total_eve_minutes"""

sns.boxplot(x=train['total_eve_minutes'])

"""7. Fitur total_eve_calls"""

sns.boxplot(x=train['total_eve_calls'])

"""8. Fitur total_eve_charge"""

sns.boxplot(x=train['total_eve_charge'])

"""9. Fitur total_night_minutes"""

sns.boxplot(x=train['total_night_minutes'])

"""10. Fitur total_night_calls"""

sns.boxplot(x=train['total_night_calls'])

"""11. Fitur total_night_charge"""

sns.boxplot(x=train['total_night_charge'])

"""12. Fitur total_intl_minutes"""

sns.boxplot(x=train['total_intl_minutes'])

"""13. Fitur total_intl_calls"""

sns.boxplot(x=train['total_intl_calls'])

"""14. Fitur total_intl_charge"""

sns.boxplot(x=train['total_intl_charge'])

"""15. Fitur number_customer_service_calls"""

sns.boxplot(x=train['number_customer_service_calls'])

"""Jika kita perhatikan kembali, pada fitur-fitur numerik di atas terdapat outliers. Selanjutnya adalah mengatasi outliers tersebut dengan metode yang telah dibahas sebelumnya yaitu metode IQR."""

Q1 = train.quantile(0.25)
Q3 = train.quantile(0.75)
IQR=Q3-Q1
train=train[~((train<(Q1-1.5*IQR))|(train>(Q3+1.5*IQR))).any(axis=1)]

# Cek ukuran dataset setelah kita drop outliers
train.shape

"""Dataset Anda sekarang telah bersih dan memiliki 3.515 sampel.

### Exploratory Data Analysis - Univariate Analysis

Selanjutnya, kita akan melakukan proses analisis data dengan teknik Univariate EDA. Pertama, Anda bagi fitur pada dataset menjadi dua bagian, yaitu numerical features dan categorical features.
"""

numerical_features = ['account_length',	'number_vmail_messages', 'total_day_minutes',	'total_day_calls', 'total_day_charge', 'total_eve_minutes',	'total_eve_calls', 'total_eve_charge',	'total_night_minutes',	'total_night_calls', 'total_night_charge',	'total_intl_calls', 'total_intl_minutes',	'total_intl_charge', 'number_customer_service_calls']
categorical_features = ['state',	'area_code',	'international_plan',	'voice_mail_plan', 'churn']

"""**Categorical Features**
1. Fitur state
"""

feature = categorical_features[0]
count = train[feature].value_counts()
percent = 100*train[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

"""Dari presentase data di atas, dapat dikatakan bahwa sampel customer cenderung tersebar merata di setiap state.

2. Fitur area_code
"""

feature = categorical_features[1]
count = train[feature].value_counts()
percent = 100*train[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

"""Dari grafik di atas, dapat kita simpulkan bahwa sebagian besar sampel customer berasal dari code area 415.

3. Fitur international_plan
"""

feature = categorical_features[2]
count = train[feature].value_counts()
percent = 100*train[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

"""Dari data persentase dapat kita simpulkan bahwa lebih dari 90% sampel customer tidak memiliki plan international.

4. Fitur voice_mail_plan
"""

feature = categorical_features[3]
count = train[feature].value_counts()
percent = 100*train[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

"""Dari data persentase dapat kita diketahui bahwa lebih dari 75% sampel customer tidak memiliki plan voice mail.

5. Fitur churn
"""

feature = categorical_features[4]
count = train[feature].value_counts()
percent = 100*train[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

"""Dari data persentase dapat kita simpulkan bahwa lebih dari 89% sampel customer bukan merupakan customer churn. Ini mengindikasikan data yang imbalance."""

train.hist(bins=50, figsize=(20,15))
plt.show()

"""Dari histogram fitur-fitur numerik, kita bisa memperoleh beberapa informasi, antara lain:
* Distribusi fitur cenderung membentuk distribusi normal.
* Pada histogram number_vmail_messages mayoritas memiliki nilai 0 dan ini berhubungan dengan fitur voice_mail_plan dimana sampel customer lebih banyak yang tidak memiliki plan voice mail.

### Exploratory Data Analysis - Multivariate Analysis

Multivariate EDA menunjukkan hubungan antara dua atau lebih variabel pada data.

**Categorical Features**

Pada tahap ini, kita akan mengecek proporsi customer churn terhadap masing-masing fitur untuk mengetahui pengaruh fitur kategori terhadap customer churn.
"""

df=train.groupby([categorical_features[0],'churn']).size()
df=df.unstack()
df.plot(kind='bar')

df=train.groupby([categorical_features[1],'churn']).size()
df=df.unstack()
df.plot(kind='bar')

df=train.groupby([categorical_features[2],'churn']).size()
df=df.unstack()
df.plot(kind='bar')

df=train.groupby([categorical_features[3],'churn']).size()
df=df.unstack()
df.plot(kind='bar')

"""Dengan mengamati proporsi customer churn terhadap fitur kategori di atas, kita memperoleh insight sebagai berikut:

* Pada fitur 'state', proporsi customer churn cenderung mirip di setiap kategorinya. Sehingga, fitur state memiliki pengaruh atau dampak yang kecil terhadap customer churn.
* Pada fitur 'area_code', diketahui proporsi customer churn di setiap kategorinya cenderung mirip. Dari sini dapat disimpulkan bahwa warna memiliki pengaruh yang rendah terhadap customer churn.
* Pada fitur 'international_plan', secara umum, customer yang memiliki plan international memiliki proporsi customer churn yang lebih tinggi dibandingan dengan yang tidak. Hal ini berarti bahwa fitur 'international_plan' memiliki pengaruh yang tinggi terhadap customer churn.
* Pada fitur 'voice_mail_plan', secara umum, customer yang memiliki plan voice mail memiliki proporsi customer churn yang lebih rendah dibandingan dengan yang tidak. Hal ini berarti bahwa fitur 'voice_mail_plan' memiliki pengaruh yang tinggi terhadap customer churn.
* Kesimpulan akhir, beberapa fitur kategori memiliki pengaruh yang rendah terhadap customer churn.

Hal ini dapat menjadi pertimbangan untuk menghilangan fitur yang memiliki pengaruh rendah. Untuk itu akan dilakukan drop untuk fitur 'state' dan 'area_code'.

"""

train.drop(['state', 'area_code'], axis=1, inplace=True) # Buang kolom yang tidak diperlukan
train

"""Data terupdate sekarang memiliki 3.515 baris dengan 18 fitur.

## **Data preparation**

### Encoding Fitur Kategori

Untuk melakukan proses encoding fitur kategori, salah satu teknik yang umum dilakukan adalah teknik one-hot-encoding.
"""

international_plan_mapping = {"no" : 0, "yes" : 1}
voice_mail_plan_mapping = {"no" : 0, "yes" : 1}
churn_mapping = {"no" : 0, "yes" : 1}

train['international_plan'] = train['international_plan'].map(international_plan_mapping)
train['voice_mail_plan'] = train['voice_mail_plan'].map(voice_mail_plan_mapping)
train['churn'] = train['churn'].map(voice_mail_plan_mapping)

train.head()

"""## **Modeling**

Pada tahap ini, kita akan mengembangkan model machine learning dengan beberapa algoritma. Kemudian, kita akan mengevaluasi performa masing-masing algoritma dan menentukan algoritma mana yang memberikan hasil prediksi terbaik.
"""

train_data = train.drop("churn",axis = 1 )
target = train['churn']

"""### Cross Validation

Pelatihan model di sini menggunakan teknik Cross Validation. Cross validation adalah metode statistik yang digunakan untuk mengevaluasi dan membandingkan algoritma pembelajaran dengan cara membagi data menjadi dua bagian: satu digunakan untuk belajar atau melatih model, satu untuk menguji model tersebut (Refaeilzadeh, et al., 2009). Metode cross validation digunakan untuk mencari akurasi dari setiap model klasifikasi.

Dalam kasus ini, proses pembagian data uji dan data latih setiap fold dilakukan secara stratified. Stratified merupakan teknik dalam cross validation untuk memastikan bahwa dalam data latih dan data uji harus ada perwakilan dari setiap kelas yang ada dengan persentase yang sama. Stratified dilakukan untuk memastikan bahwa dalam setiap fold merupakan representasi data yang baik (Refaeilzadeh, et al., 2009). Hal ini cocok untuk menangani data dengan kondisi imbalance.

### Naive Bayes
"""

k_fold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)

nb = GaussianNB()
scoring = 'accuracy'
score = cross_val_score(nb, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)
print(score)

"""### Decision Tree"""

tree = DecisionTreeClassifier()
score = cross_val_score(tree, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)
print(score)

"""### KNN"""

knn = KNeighborsClassifier()
score = cross_val_score(knn, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)
print(score)

"""### Random Forest"""

rf = RandomForestClassifier()
score = cross_val_score(rf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)
print(score)

"""### Boosting"""

boosting = AdaBoostClassifier()
score = cross_val_score(boosting, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)
print(score)

"""### SVC"""

svc = SVC()
score = cross_val_score(svc, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)
print(score)

"""## Evaluation

Metrik yang akan kita gunakan pada prediksi ini adalah accuracy.
"""

# Buat variabel mse yang isinya adalah dataframe nilai accuracy data train dan test pada masing-masing algoritma
acc = pd.DataFrame(columns=['Accuracy'], index=['KNN', 'RF', 'Boosting', 'Naive Bayes', 'Decision Tree', 'SVC'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': rf, 'Boosting': boosting, 'Naive Bayes': nb, 'Decision Tree': tree, 'SVC': svc}

# Hitung accuracy masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    acc.loc[name, 'Accuracy'] = cross_val_score(model, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring).mean()

# Panggil acc
acc

"""### Plot Accuracy Beberapa Algoritma"""

fig, ax = plt.subplots()
acc.sort_values(by='Accuracy', ascending=True).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Dari output di atas, terlihat bahwa, model **Random Forest (RF)** memberikan nilai accuracy yang paling tinggi. Sedangkan model dengan algoritma SVC memiliki accuracy yang paling kecil. Model inilah yang akan kita pilih sebagai model terbaik untuk melakukan prediksi customer churn.

Random forest merupakan salah satu model machine learning yang termasuk ke dalam kategori ensemble (group) learning. Ide dibalik model ensemble adalah sekelompok model yang bekerja bersama menyelesaikan masalah. Sehingga, tingkat keberhasilan akan lebih tinggi dibanding model yang bekerja sendirian.

Selanjutnya akan dicari parameter terbaik dengan teknik Grid Search.
"""

model = RandomForestClassifier()

# Define Parameters
parameters = {
    'n_estimators': [64, 128, 256],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth': [2, 8, 16, None],
    'criterion': ['gini', 'entropy']
}

# Build the grid search
grid_search = GridSearchCV(model, parameters, cv=5)
grid_search.fit(train_data,target)

# Summarize the results in a readable format
print("RandomForestClassifier GridSearch score: "+str(grid_search.best_score_))
print("RandomForestClassifier GridSearch params: ")
print(grid_search.best_params_)

best_model = RandomForestClassifier(random_state=0, max_features='sqrt', n_estimators= 256, max_depth=16, criterion='gini')

best_model.fit(train_data,target)

"""## Prediction"""

test.drop(['state', 'area_code'], axis=1, inplace=True) # Buang kolom yang tidak diperlukan
test['international_plan'] = test['international_plan'].map(international_plan_mapping)
test['voice_mail_plan'] = test['voice_mail_plan'].map(voice_mail_plan_mapping)
test

test_data = test.drop("id",axis = 1 )
test_id = test['id']
test_data

prediction = best_model.predict(test_data)
prediction

submission = pd.DataFrame({
        "cutomer_id": test_id,
        "churn": prediction
    })
submission.head()

submission.to_csv("submit.csv", index = False)

test_data['churn'] = submission['churn']
test_data.head()

"""## Referensi

*   Refaeilzadeh, P., Tang, L. & Liu, H., 2009. Cross-Validation. Dalam: Encyclopedia of Database Systems. Boston: Springer US
"""